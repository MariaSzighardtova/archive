{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "logistic_results = {\n",
    "    'Model': ['Logistic Regression'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = decision_tree.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "decision_tree_results = {\n",
    "    'Model': ['Decision Tree'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.best_estimator_.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "svm_results = {\n",
    "    'Model': ['SVM'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rfc.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = rfc.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "random_forest_results = {\n",
    "    'Model': ['Random Forest'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gs.best_estimator_.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "adaboost_results = {\n",
    "    'Model': ['Adaboost'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mlp_best.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = mlp_best.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "mlp_early_results = {\n",
    "    'Model': ['MLP Classifier - Early Stopping'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier - No Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mlp_best3.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_pred = mlp_best3.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "mlp_no_results = {\n",
    "    'Model': ['MLP Classifier - No Stopping'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural with KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "print(f'Train Accuracy: {train_accuracy}')\n",
    "_, test_accuracy = classifier.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "neural_keras_results = {\n",
    "    'Model': ['Neural Network with Keras'],\n",
    "    'Train Accuracy': [train_accuracy],\n",
    "    'Test Accuracy': [test_accuracy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_results_df = pd.DataFrame(logistic_results)\n",
    "decision_tree_results_df = pd.DataFrame(decision_tree_results)\n",
    "svm_results_df = pd.DataFrame(svm_results)\n",
    "random_forest_results_df = pd.DataFrame(random_forest_results)\n",
    "adaboost_results_df = pd.DataFrame(adaboost_results)\n",
    "mlp_early_results_df = pd.DataFrame(mlp_early_results)\n",
    "mlp_no_results_df = pd.DataFrame(mlp_no_results)\n",
    "neural_keras_results_df = pd.DataFrame(neural_keras_results)\n",
    "\n",
    "\n",
    "model_results = pd.concat([logistic_results_df, decision_tree_results_df, svm_results_df, \n",
    "                 random_forest_results_df, adaboost_results_df, mlp_early_results_df, \n",
    "                 mlp_no_results_df, neural_keras_results_df], ignore_index=True)\n",
    "\n",
    "\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the DataFrame for easier plotting\n",
    "model_results_transposed = model_results.transpose()\n",
    "\n",
    "# Extract the model names\n",
    "models = model_results_transposed.iloc[0].tolist()\n",
    "\n",
    "# Extract the train and test accuracy values\n",
    "train_accuracy = model_results_transposed.iloc[1].tolist()\n",
    "test_accuracy = model_results_transposed.iloc[2].tolist()\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "index = range(len(models))\n",
    "train_bar_positions = [i for i in index]\n",
    "test_bar_positions = [i + bar_width for i in index]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(train_bar_positions, train_accuracy, bar_width, label='Train Accuracy', color='lightblue')\n",
    "plt.bar(test_bar_positions, test_accuracy, bar_width, label='Test Accuracy', color='lightcoral')\n",
    "\n",
    "# Set the x-axis labels\n",
    "plt.xticks([i + bar_width / 2 for i in index], models, rotation=45, ha='right')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
